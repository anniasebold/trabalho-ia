{"cells":[{"cell_type":"markdown","metadata":{"id":"Yxd4GpH8kFTE"},"source":["### Preparação do ambiente"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":23904,"status":"ok","timestamp":1731944883539,"user":{"displayName":"WILSON DA SILVA GOROSTHIDES NETO","userId":"18202662512863748273"},"user_tz":240},"id":"Bm6brhlsOcBR","outputId":"72a4fe25-14f0-434e-a717-a9142a1b2044"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: asttokens==2.4.1 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (2.4.1)\n","Requirement already satisfied: click==8.1.7 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (8.1.7)\n","Requirement already satisfied: comm==0.2.2 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (0.2.2)\n","Requirement already satisfied: debugpy==1.8.9 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (1.8.9)\n","Requirement already satisfied: decorator==5.1.1 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (5.1.1)\n","Requirement already satisfied: exceptiongroup==1.2.2 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (1.2.2)\n","Requirement already satisfied: executing==2.1.0 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (2.1.0)\n","Requirement already satisfied: ipykernel==6.29.5 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (6.29.5)\n","Requirement already satisfied: ipython==8.29.0 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (8.29.0)\n","Requirement already satisfied: jedi==0.19.2 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (0.19.2)\n","Requirement already satisfied: joblib==1.4.2 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (1.4.2)\n","Requirement already satisfied: jupyter_client==8.6.3 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (8.6.3)\n","Requirement already satisfied: jupyter_core==5.7.2 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (5.7.2)\n","Requirement already satisfied: matplotlib-inline==0.1.7 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 14)) (0.1.7)\n","Requirement already satisfied: nest-asyncio==1.6.0 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 15)) (1.6.0)\n","Requirement already satisfied: nltk==3.9.1 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 16)) (3.9.1)\n","Requirement already satisfied: numpy==2.1.3 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 17)) (2.1.3)\n","Requirement already satisfied: packaging==24.2 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 18)) (24.2)\n","Requirement already satisfied: pandas==2.2.3 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 19)) (2.2.3)\n","Requirement already satisfied: parso==0.8.4 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 20)) (0.8.4)\n","Requirement already satisfied: pexpect==4.9.0 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 21)) (4.9.0)\n","Requirement already satisfied: platformdirs==4.3.6 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 22)) (4.3.6)\n","Requirement already satisfied: prompt_toolkit==3.0.48 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 23)) (3.0.48)\n","Requirement already satisfied: psutil==6.1.0 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 24)) (6.1.0)\n","Requirement already satisfied: ptyprocess==0.7.0 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 25)) (0.7.0)\n","Requirement already satisfied: pure_eval==0.2.3 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 26)) (0.2.3)\n","Requirement already satisfied: Pygments==2.18.0 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 27)) (2.18.0)\n","Requirement already satisfied: PyPDF2==3.0.1 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 28)) (3.0.1)\n","Requirement already satisfied: python-dateutil==2.9.0.post0 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 29)) (2.9.0.post0)\n","Requirement already satisfied: pytz==2024.2 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 30)) (2024.2)\n","Requirement already satisfied: pyzmq==26.2.0 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 31)) (26.2.0)\n","Requirement already satisfied: regex==2024.11.6 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 32)) (2024.11.6)\n","Requirement already satisfied: scikit-learn==1.5.2 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 33)) (1.5.2)\n","Requirement already satisfied: scipy==1.14.1 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 34)) (1.14.1)\n","Requirement already satisfied: six==1.16.0 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 35)) (1.16.0)\n","Requirement already satisfied: sklearn-pandas==2.2.0 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 36)) (2.2.0)\n","Requirement already satisfied: stack-data==0.6.3 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 37)) (0.6.3)\n","Requirement already satisfied: threadpoolctl==3.5.0 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 38)) (3.5.0)\n","Requirement already satisfied: tornado==6.4.2 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 39)) (6.4.2)\n","Requirement already satisfied: tqdm==4.67.0 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 40)) (4.67.0)\n","Requirement already satisfied: traitlets==5.14.3 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 41)) (5.14.3)\n","Requirement already satisfied: typing_extensions==4.12.2 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 42)) (4.12.2)\n","Requirement already satisfied: tzdata==2024.2 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 43)) (2024.2)\n","Requirement already satisfied: wcwidth==0.2.13 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 44)) (0.2.13)\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install -r requirements.txt "]},{"cell_type":"markdown","metadata":{"id":"dLDDkGahs01Y"},"source":["# Imports, extração e geração do Bag of Words"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7847,"status":"ok","timestamp":1731944936845,"user":{"displayName":"WILSON DA SILVA GOROSTHIDES NETO","userId":"18202662512863748273"},"user_tz":240},"id":"RxaDyVId4oS9","outputId":"04fd196a-2fc1-47bd-d9ff-4aa34939d9d6"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to\n","[nltk_data]     /home/anniasebold/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to\n","[nltk_data]     /home/anniasebold/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt_tab to\n","[nltk_data]     /home/anniasebold/nltk_data...\n","[nltk_data]   Package punkt_tab is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import os\n","import PyPDF2\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","import nltk\n","\n","# Baixar recursos do NLTK (apenas na primeira execução)\n","nltk.download(\"punkt\")\n","nltk.download(\"stopwords\")\n","nltk.download('punkt_tab')\n"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":281,"status":"ok","timestamp":1731944941380,"user":{"displayName":"WILSON DA SILVA GOROSTHIDES NETO","userId":"18202662512863748273"},"user_tz":240},"id":"dMElA0Nf4xAZ"},"outputs":[],"source":["# Função para extrair texto de PDFs\n","def pdf_para_txt(caminho_pdf):\n","    with open(caminho_pdf, \"rb\") as f:\n","        leitor = PyPDF2.PdfReader(f)\n","        texto = \"\"\n","        for pagina in range(len(leitor.pages)):\n","            texto += leitor.pages[pagina].extract_text()\n","    return texto\n","\n","# Diretórios com os PDFs\n","diretorios = {\n","  'poesia': 'texts/poetry',\n","  'prosa':  'texts/prose',\n","  'jornalismo': 'texts/jornalism'\n","}\n","\n","# Função para limpar e remover stopwords\n","def limpar_texto(texto):\n","    stop_words = set(stopwords.words(\"english\"))\n","    palavras = word_tokenize(texto.lower())\n","    palavras_limpa = [palavra for palavra in palavras\n","                      if palavra.isalnum() and palavra not in stop_words]\n","    return \" \".join(palavras_limpa)"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":50778,"status":"ok","timestamp":1731945013888,"user":{"displayName":"WILSON DA SILVA GOROSTHIDES NETO","userId":"18202662512863748273"},"user_tz":240},"id":"Oya21I-c41FE"},"outputs":[],"source":["# Extraindo textos e gerando classes\n","textos = []\n","classes = []\n","\n","for classe, caminho in diretorios.items():\n","    for arquivo in os.listdir(caminho):\n","        if arquivo.endswith('.pdf'):\n","            texto = pdf_para_txt(os.path.join(caminho, arquivo))\n","            texto_limpo = limpar_texto(texto)\n","            textos.append(texto_limpo)\n","            classes.append(classe)\n","\n","# Criando a matriz Bag of Words\n","vectorizer = TfidfVectorizer()\n","X = vectorizer.fit_transform(textos)"]},{"cell_type":"markdown","metadata":{"id":"eCawoV059ou7"},"source":["# Algoritmos de aprendizado super-visionado\n","\n","Para avaliar o desempenho dos algoritmos, ser ̃ao utilizadas as seguintes métricas:\n","\n","*   Acuracia: Proporção de previsões corretas em relação ao total de exemplo. Pode ser obtida com a função accuracy score.\n","*   F1-Score: Média harmônica da precisão e revocação, especialmnte útil para classes desbalanceadas. Pode ser calculada com f1 score.\n","\n","Cada algoritmo será avaliado utilizando o procedimento de validação cruzada estratificada com 10 folds. A validação cruzada consiste em dividir os dados em 10 subconjuntos (folds), utilizando cada um como conjunto de teste e os demais como treino, em rodadas sucessivas. Esse método é implementado com a função StratifiedKFold. Para cada rodada da validação cruzada, serão coletados os seguintes valores:\n","\n","\n","*   Acurácia de cada fold;\n","*   F1-score de cada fold."]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":257,"status":"ok","timestamp":1731945017571,"user":{"displayName":"WILSON DA SILVA GOROSTHIDES NETO","userId":"18202662512863748273"},"user_tz":240},"id":"brpp2OK_8Yrr"},"outputs":[],"source":["import numpy as np\n","from sklearn.model_selection import GridSearchCV, StratifiedKFold\n","from sklearn.metrics import f1_score, make_scorer\n","from sklearn.model_selection import cross_val_score"]},{"cell_type":"markdown","metadata":{"id":"7Z4o6l6LArjx"},"source":["# Hiperparâmetros e Otimização\n","\n","Para cada algoritmo, deverão ser testadas ao menos duas combinações de hiperparâmetros.\n","A otimização desses parâmetros pode ser realizada utilizando o método GridSearchCV, disponível no Scikit-learn."]},{"cell_type":"markdown","metadata":{"id":"cq3mYH7bEDvX"},"source":["# KNN"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2847,"status":"ok","timestamp":1731720829348,"user":{"displayName":"ANNIA LUIZA SEBOLD DE ALMEIDA","userId":"04748302660145563818"},"user_tz":240},"id":"0pMAHnPTEDcJ","outputId":"c43b9c90-aa99-4685-ccba-bf6f8634acf6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 10 folds for each of 6 candidates, totalling 60 fits\n","Melhores parâmetros encontrados: [{'n_neighbors': 7, 'weights': 'distance'}, {'n_neighbors': 7, 'weights': 'uniform'}]\n"]}],"source":["from sklearn.neighbors import KNeighborsClassifier\n","\n","# Convertendo as classes para um array numpy\n","y = np.array(classes)\n","\n","# Criando o GridSearchCV para buscar os melhores hiperparâmetros\n","grid_search = GridSearchCV(\n","    estimator=KNeighborsClassifier(),\n","    param_grid={\n","    'n_neighbors': [3, 5, 7],\n","    'weights': ['uniform', 'distance']\n","    },\n","    scoring=make_scorer(f1_score, average='weighted'),\n","    cv=10,  # Validação cruzada com 10 folds\n","    n_jobs=1,  # Paralelismo\n","    verbose=1   # Mostrar progresso\n",")\n","\n","# Executando o GridSearchCV\n","grid_search.fit(X, y)\n","\n","# Obtendo as duas melhores combinações de parâmetros\n","resultados = grid_search.cv_results_\n","melhores_indices = np.argsort(resultados['mean_test_score'])[::-1][:2]\n","\n","melhores_parametros = [resultados['params'][idx] for idx in melhores_indices]\n","\n","print(f\"Melhores parâmetros encontrados: {melhores_parametros}\")\n","\n"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":586,"status":"ok","timestamp":1731712672417,"user":{"displayName":"ANNIA LUIZA SEBOLD DE ALMEIDA","userId":"04748302660145563818"},"user_tz":240},"id":"Xs3BaggRVvw0","outputId":"ecaea93e-1110-47e1-f9c3-7012ec82a5c2"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","KNN para os hiperparâmetros: {'n_neighbors': 7, 'weights': 'distance'}\n","\n","Fold 1\n","Acurácia = 1.0000\n","F1-Score = 1.0000\n","\n","Fold 2\n","Acurácia = 0.9000\n","F1-Score = 0.8993\n","\n","Fold 3\n","Acurácia = 0.9333\n","F1-Score = 0.9327\n","\n","Fold 4\n","Acurácia = 1.0000\n","F1-Score = 1.0000\n","\n","Fold 5\n","Acurácia = 0.9333\n","F1-Score = 0.9327\n","\n","Fold 6\n","Acurácia = 0.9000\n","F1-Score = 0.9019\n","\n","Fold 7\n","Acurácia = 0.9667\n","F1-Score = 0.9666\n","\n","Fold 8\n","Acurácia = 0.9333\n","F1-Score = 0.9327\n","\n","Fold 9\n","Acurácia = 0.9333\n","F1-Score = 0.9346\n","\n","Fold 10\n","Acurácia = 0.9333\n","F1-Score = 0.9332\n","\n","Média de Acurácia: 0.9433\n","Desvio Padrão de Acurácia: 0.0335\n","Média de F1-Score: 0.9434\n","Desvio Padrão de F1-Score: 0.0334\n","\n","KNN para os hiperparâmetros: {'n_neighbors': 7, 'weights': 'uniform'}\n","\n","Fold 1\n","Acurácia = 0.9667\n","F1-Score = 0.9666\n","\n","Fold 2\n","Acurácia = 0.8667\n","F1-Score = 0.8669\n","\n","Fold 3\n","Acurácia = 0.9000\n","F1-Score = 0.8977\n","\n","Fold 4\n","Acurácia = 1.0000\n","F1-Score = 1.0000\n","\n","Fold 5\n","Acurácia = 0.9333\n","F1-Score = 0.9327\n","\n","Fold 6\n","Acurácia = 0.9000\n","F1-Score = 0.9019\n","\n","Fold 7\n","Acurácia = 0.9333\n","F1-Score = 0.9327\n","\n","Fold 8\n","Acurácia = 0.9333\n","F1-Score = 0.9327\n","\n","Fold 9\n","Acurácia = 0.8667\n","F1-Score = 0.8681\n","\n","Fold 10\n","Acurácia = 0.9333\n","F1-Score = 0.9332\n","\n","Média de Acurácia: 0.9233\n","Desvio Padrão de Acurácia: 0.0396\n","Média de F1-Score: 0.9232\n","Desvio Padrão de F1-Score: 0.0393\n"]}],"source":["# Executando com as duas melhores combinações\n","for params in melhores_parametros:\n","  print(f\"\\nKNN para os hiperparâmetros: {params}\\n\")\n","\n","  knn = KNeighborsClassifier(\n","      n_neighbors=params['n_neighbors'],\n","      weights=params['weights']\n","    )\n","\n","  kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n","\n","  accuracies_fold = cross_val_score(knn, X, y, cv=kf, scoring='accuracy')\n","  f1_scores_fold = cross_val_score(knn, X, y, cv=kf, scoring='f1_weighted')\n","\n","  for fold, (train_index, test_index) in enumerate(kf.split(X, y), 1):\n","      X_train, X_test = X[train_index], X[test_index]\n","      y_train, y_test = y[train_index], y[test_index]\n","\n","      knn.fit(X_train, y_train)\n","      y_pred = knn.predict(X_test)\n","\n","      # Acurácia e o F1-Score do fold atual\n","      print(f\"Fold {fold}\\nAcurácia = {accuracies_fold[fold-1]:.4f}\\nF1-Score = {f1_scores_fold[fold-1]:.4f}\\n\")\n","\n","  # Cálculo das médias e o desvio padrão\n","  media_acuracia = np.mean(accuracies_fold)\n","  desvio_acuracia = np.std(accuracies_fold)\n","\n","  media_f1 = np.mean(f1_scores_fold)\n","  desvio_f1 = np.std(f1_scores_fold)\n","\n","  print(f\"Média de Acurácia: {media_acuracia:.4f}\")\n","  print(f\"Desvio Padrão de Acurácia: {desvio_acuracia:.4f}\")\n","  print(f\"Média de F1-Score: {media_f1:.4f}\")\n","  print(f\"Desvio Padrão de F1-Score: {desvio_f1:.4f}\")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"k7Gv16xtheGm"},"source":["# Árvore de Decisão"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2946,"status":"ok","timestamp":1731712677860,"user":{"displayName":"ANNIA LUIZA SEBOLD DE ALMEIDA","userId":"04748302660145563818"},"user_tz":240},"id":"GT3p4yU3iPVm","outputId":"56410a5f-9894-4f56-8e9b-81b40ba0440f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 10 folds for each of 8 candidates, totalling 80 fits\n","Melhores parâmetros encontrados: [{'criterion': 'entropy', 'max_depth': 30}, {'criterion': 'entropy', 'max_depth': 20}]\n"]}],"source":["from sklearn.tree import DecisionTreeClassifier\n","\n","y = np.array(classes)\n","\n","grid_search = GridSearchCV(\n","    estimator=DecisionTreeClassifier(random_state=42),\n","    param_grid={\n","      'criterion': ['gini', 'entropy'],  # Critérios para a divisão\n","      'max_depth': [None, 10, 20, 30],   # Profundidade máxima da árvore\n","    },\n","    scoring=make_scorer(f1_score, average='weighted'),\n","    cv=10,\n","    n_jobs=1,\n","    verbose=1\n",")\n","\n","grid_search.fit(X, y)\n","\n","resultados = grid_search.cv_results_\n","melhores_indices = np.argsort(resultados['mean_test_score'])[::-1][:2]\n","\n","melhores_parametros = [resultados['params'][idx] for idx in melhores_indices]\n","\n","print(f\"Melhores parâmetros encontrados: {melhores_parametros}\")\n"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3558,"status":"ok","timestamp":1731712683760,"user":{"displayName":"ANNIA LUIZA SEBOLD DE ALMEIDA","userId":"04748302660145563818"},"user_tz":240},"id":"RuQiKpq0iw7q","outputId":"3a88f631-4173-4e0e-bed0-bfca9c714b1c"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Árvore de Decisão para os hiperparâmetros: {'criterion': 'entropy', 'max_depth': 30}\n","\n","Fold 1\n","Acurácia = 1.0000\n","F1-Score = 1.0000\n","\n","Fold 2\n","Acurácia = 0.9333\n","F1-Score = 0.9332\n","\n","Fold 3\n","Acurácia = 1.0000\n","F1-Score = 1.0000\n","\n","Fold 4\n","Acurácia = 1.0000\n","F1-Score = 1.0000\n","\n","Fold 5\n","Acurácia = 1.0000\n","F1-Score = 1.0000\n","\n","Fold 6\n","Acurácia = 0.9667\n","F1-Score = 0.9666\n","\n","Fold 7\n","Acurácia = 0.9000\n","F1-Score = 0.8997\n","\n","Fold 8\n","Acurácia = 0.9667\n","F1-Score = 0.9666\n","\n","Fold 9\n","Acurácia = 1.0000\n","F1-Score = 1.0000\n","\n","Fold 10\n","Acurácia = 0.9333\n","F1-Score = 0.9327\n","\n","Média de Acurácia: 0.9700\n","Desvio Padrão de Acurácia: 0.0348\n","Média de F1-Score: 0.9699\n","Desvio Padrão de F1-Score: 0.0349\n","\n","Árvore de Decisão para os hiperparâmetros: {'criterion': 'entropy', 'max_depth': 20}\n","\n","Fold 1\n","Acurácia = 1.0000\n","F1-Score = 1.0000\n","\n","Fold 2\n","Acurácia = 0.9333\n","F1-Score = 0.9332\n","\n","Fold 3\n","Acurácia = 1.0000\n","F1-Score = 1.0000\n","\n","Fold 4\n","Acurácia = 1.0000\n","F1-Score = 1.0000\n","\n","Fold 5\n","Acurácia = 1.0000\n","F1-Score = 1.0000\n","\n","Fold 6\n","Acurácia = 0.9667\n","F1-Score = 0.9666\n","\n","Fold 7\n","Acurácia = 0.9000\n","F1-Score = 0.8997\n","\n","Fold 8\n","Acurácia = 0.9667\n","F1-Score = 0.9666\n","\n","Fold 9\n","Acurácia = 1.0000\n","F1-Score = 1.0000\n","\n","Fold 10\n","Acurácia = 0.9333\n","F1-Score = 0.9327\n","\n","Média de Acurácia: 0.9700\n","Desvio Padrão de Acurácia: 0.0348\n","Média de F1-Score: 0.9699\n","Desvio Padrão de F1-Score: 0.0349\n"]}],"source":["# Executando com as duas melhores combinações\n","for params in melhores_parametros:\n","  print(f\"\\nÁrvore de Decisão para os hiperparâmetros: {params}\\n\")\n","\n","  dtc = DecisionTreeClassifier(\n","      random_state=42,\n","      criterion=params['criterion'],\n","      max_depth=params['max_depth']\n","    )\n","\n","  kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n","\n","  accuracies_fold = cross_val_score(dtc, X, y, cv=kf, scoring='accuracy')\n","  f1_scores_fold = cross_val_score(dtc, X, y, cv=kf, scoring='f1_weighted')\n","\n","  for fold, (train_index, test_index) in enumerate(kf.split(X, y), 1):\n","      X_train, X_test = X[train_index], X[test_index]\n","      y_train, y_test = y[train_index], y[test_index]\n","\n","      dtc.fit(X_train, y_train)\n","      y_pred = dtc.predict(X_test)\n","\n","      # Acurácia e o F1-Score do fold atual\n","      print(f\"Fold {fold}\\nAcurácia = {accuracies_fold[fold-1]:.4f}\\nF1-Score = {f1_scores_fold[fold-1]:.4f}\\n\")\n","\n","  # Cálculo das médias e o desvio padrão\n","  media_acuracia = np.mean(accuracies_fold)\n","  desvio_acuracia = np.std(accuracies_fold)\n","\n","  media_f1 = np.mean(f1_scores_fold)\n","  desvio_f1 = np.std(f1_scores_fold)\n","\n","  print(f\"Média de Acurácia: {media_acuracia:.4f}\")\n","  print(f\"Desvio Padrão de Acurácia: {desvio_acuracia:.4f}\")\n","  print(f\"Média de F1-Score: {media_f1:.4f}\")\n","  print(f\"Desvio Padrão de F1-Score: {desvio_f1:.4f}\")"]},{"cell_type":"markdown","metadata":{"id":"4y-g8CN2jMdJ"},"source":["# Naive Bayes"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4772,"status":"ok","timestamp":1731713177886,"user":{"displayName":"ANNIA LUIZA SEBOLD DE ALMEIDA","userId":"04748302660145563818"},"user_tz":240},"id":"psRH5CLijWj_","outputId":"cc0597ac-4034-4a50-def8-2551f4c0d680"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 10 folds for each of 4 candidates, totalling 40 fits\n","Melhores parâmetros encontrados: [{'priors': [0.3333333333333333, 0.3333333333333333, 0.3333333333333333], 'var_smoothing': 1e-07}, {'priors': [0.3333333333333333, 0.3333333333333333, 0.3333333333333333], 'var_smoothing': 1e-09}]\n"]}],"source":["from sklearn.naive_bayes import GaussianNB\n","\n","y = np.array(classes)\n","\n","# Convertendo X para um array denso\n","X_naive = X.toarray()\n","\n","grid_search = GridSearchCV(\n","    estimator=GaussianNB(),\n","    param_grid={\n","        'var_smoothing': [1e-9, 1e-7],  # Diferentes valores de suavização\n","        'priors': [None, [1/3, 1/3, 1/3]],  # Testando a distribuição de priors\n","    },\n","    scoring=make_scorer(f1_score, average='weighted'),\n","    cv=10,\n","    n_jobs=1,\n","    verbose=1\n",")\n","\n","grid_search.fit(X_naive, y)\n","\n","resultados = grid_search.cv_results_\n","melhores_indices = np.argsort(resultados['mean_test_score'])[::-1][:2]\n","\n","melhores_parametros = [resultados['params'][idx] for idx in melhores_indices]\n","\n","print(f\"Melhores parâmetros encontrados: {melhores_parametros}\")\n"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5189,"status":"ok","timestamp":1731713186234,"user":{"displayName":"ANNIA LUIZA SEBOLD DE ALMEIDA","userId":"04748302660145563818"},"user_tz":240},"id":"_fS9gZIDkz0g","outputId":"0a4e07d2-bd4c-435f-a1af-c3f223ae750b"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Naive Bayes para os hiperparâmetros: {'priors': [0.3333333333333333, 0.3333333333333333, 0.3333333333333333], 'var_smoothing': 1e-07}\n","\n","Fold 1\n","Acurácia = 0.8000\n","F1-Score = 0.7802\n","\n","Fold 2\n","Acurácia = 0.8000\n","F1-Score = 0.7944\n","\n","Fold 3\n","Acurácia = 0.8000\n","F1-Score = 0.7802\n","\n","Fold 4\n","Acurácia = 0.9333\n","F1-Score = 0.9327\n","\n","Fold 5\n","Acurácia = 0.8667\n","F1-Score = 0.8649\n","\n","Fold 6\n","Acurácia = 0.8000\n","F1-Score = 0.7908\n","\n","Fold 7\n","Acurácia = 0.9000\n","F1-Score = 0.8995\n","\n","Fold 8\n","Acurácia = 0.8333\n","F1-Score = 0.8318\n","\n","Fold 9\n","Acurácia = 0.8667\n","F1-Score = 0.8649\n","\n","Fold 10\n","Acurácia = 0.7667\n","F1-Score = 0.7532\n","\n","Média de Acurácia: 0.8367\n","Desvio Padrão de Acurácia: 0.0504\n","Média de F1-Score: 0.8293\n","Desvio Padrão de F1-Score: 0.0561\n","\n","Naive Bayes para os hiperparâmetros: {'priors': [0.3333333333333333, 0.3333333333333333, 0.3333333333333333], 'var_smoothing': 1e-09}\n","\n","Fold 1\n","Acurácia = 0.8000\n","F1-Score = 0.7802\n","\n","Fold 2\n","Acurácia = 0.8000\n","F1-Score = 0.7944\n","\n","Fold 3\n","Acurácia = 0.8000\n","F1-Score = 0.7802\n","\n","Fold 4\n","Acurácia = 0.9333\n","F1-Score = 0.9327\n","\n","Fold 5\n","Acurácia = 0.8667\n","F1-Score = 0.8649\n","\n","Fold 6\n","Acurácia = 0.8000\n","F1-Score = 0.7908\n","\n","Fold 7\n","Acurácia = 0.9000\n","F1-Score = 0.8995\n","\n","Fold 8\n","Acurácia = 0.8333\n","F1-Score = 0.8318\n","\n","Fold 9\n","Acurácia = 0.8667\n","F1-Score = 0.8649\n","\n","Fold 10\n","Acurácia = 0.7667\n","F1-Score = 0.7532\n","\n","Média de Acurácia: 0.8367\n","Desvio Padrão de Acurácia: 0.0504\n","Média de F1-Score: 0.8293\n","Desvio Padrão de F1-Score: 0.0561\n"]}],"source":["# Executando com as duas melhores combinações\n","for params in melhores_parametros:\n","  print(f\"\\nNaive Bayes para os hiperparâmetros: {params}\\n\")\n","\n","  gnb = GaussianNB(\n","      var_smoothing=params['var_smoothing'],\n","      priors=params['priors']\n","    )\n","\n","  kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n","\n","  accuracies_fold = cross_val_score(gnb, X_naive, y, cv=kf, scoring='accuracy')\n","  f1_scores_fold = cross_val_score(gnb, X_naive, y, cv=kf, scoring='f1_weighted')\n","\n","  for fold, (train_index, test_index) in enumerate(kf.split(X, y), 1):\n","      X_train, X_test = X_naive[train_index], X_naive[test_index]\n","      y_train, y_test = y[train_index], y[test_index]\n","\n","      gnb.fit(X_train, y_train)\n","      y_pred = gnb.predict(X_test)\n","\n","      # Acurácia e o F1-Score do fold atual\n","      print(f\"Fold {fold}\\nAcurácia = {accuracies_fold[fold-1]:.4f}\\nF1-Score = {f1_scores_fold[fold-1]:.4f}\\n\")\n","\n","  # Cálculo das médias e o desvio padrão\n","  media_acuracia = np.mean(accuracies_fold)\n","  desvio_acuracia = np.std(accuracies_fold)\n","\n","  media_f1 = np.mean(f1_scores_fold)\n","  desvio_f1 = np.std(f1_scores_fold)\n","\n","  print(f\"Média de Acurácia: {media_acuracia:.4f}\")\n","  print(f\"Desvio Padrão de Acurácia: {desvio_acuracia:.4f}\")\n","  print(f\"Média de F1-Score: {media_f1:.4f}\")\n","  print(f\"Desvio Padrão de F1-Score: {desvio_f1:.4f}\")"]},{"cell_type":"markdown","metadata":{"id":"4TqWJDr_l0CY"},"source":["# Regressão Logística"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7438,"status":"ok","timestamp":1731713213343,"user":{"displayName":"ANNIA LUIZA SEBOLD DE ALMEIDA","userId":"04748302660145563818"},"user_tz":240},"id":"AfSzQyVOl_Px","outputId":"e7da115d-d71d-49fa-8241-fc7e976ab3f3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 10 folds for each of 6 candidates, totalling 60 fits\n","Melhores parâmetros encontrados: [{'C': 10, 'solver': 'liblinear'}, {'C': 10, 'solver': 'lbfgs'}]\n"]}],"source":["from sklearn.linear_model import LogisticRegression\n","\n","y = np.array(classes)\n","\n","grid_search = GridSearchCV(\n","    estimator=LogisticRegression(random_state=42, max_iter=1000),\n","    param_grid={\n","      'C': [0.1, 1, 10],  # Parâmetros de regularização\n","      'solver': ['lbfgs', 'liblinear']\n","    },\n","    scoring=make_scorer(f1_score, average='weighted'),\n","    cv=10,\n","    n_jobs=1,\n","    verbose=1\n",")\n","\n","grid_search.fit(X, y)\n","\n","resultados = grid_search.cv_results_\n","melhores_indices = np.argsort(resultados['mean_test_score'])[::-1][:2]\n","\n","melhores_parametros = [resultados['params'][idx] for idx in melhores_indices]\n","\n","print(f\"Melhores parâmetros encontrados: {melhores_parametros}\")\n","\n"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14259,"status":"ok","timestamp":1731713271689,"user":{"displayName":"ANNIA LUIZA SEBOLD DE ALMEIDA","userId":"04748302660145563818"},"user_tz":240},"id":"GvcJKRZhnE1B","outputId":"2d1fb4a0-f761-47fc-eb92-58e3f8f29755"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Regressão Logística para os hiperparâmetros: {'C': 10, 'solver': 'liblinear'}\n","\n","Fold 1\n","Acurácia = 1.0000\n","F1-Score = 1.0000\n","\n","Fold 2\n","Acurácia = 1.0000\n","F1-Score = 1.0000\n","\n","Fold 3\n","Acurácia = 1.0000\n","F1-Score = 1.0000\n","\n","Fold 4\n","Acurácia = 1.0000\n","F1-Score = 1.0000\n","\n","Fold 5\n","Acurácia = 1.0000\n","F1-Score = 1.0000\n","\n","Fold 6\n","Acurácia = 0.9667\n","F1-Score = 0.9666\n","\n","Fold 7\n","Acurácia = 1.0000\n","F1-Score = 1.0000\n","\n","Fold 8\n","Acurácia = 1.0000\n","F1-Score = 1.0000\n","\n","Fold 9\n","Acurácia = 1.0000\n","F1-Score = 1.0000\n","\n","Fold 10\n","Acurácia = 1.0000\n","F1-Score = 1.0000\n","\n","Média de Acurácia: 0.9967\n","Desvio Padrão de Acurácia: 0.0100\n","Média de F1-Score: 0.9967\n","Desvio Padrão de F1-Score: 0.0100\n","\n","Regressão Logística para os hiperparâmetros: {'C': 10, 'solver': 'lbfgs'}\n","\n","Fold 1\n","Acurácia = 1.0000\n","F1-Score = 1.0000\n","\n","Fold 2\n","Acurácia = 1.0000\n","F1-Score = 1.0000\n","\n","Fold 3\n","Acurácia = 1.0000\n","F1-Score = 1.0000\n","\n","Fold 4\n","Acurácia = 1.0000\n","F1-Score = 1.0000\n","\n","Fold 5\n","Acurácia = 1.0000\n","F1-Score = 1.0000\n","\n","Fold 6\n","Acurácia = 0.9667\n","F1-Score = 0.9666\n","\n","Fold 7\n","Acurácia = 1.0000\n","F1-Score = 1.0000\n","\n","Fold 8\n","Acurácia = 1.0000\n","F1-Score = 1.0000\n","\n","Fold 9\n","Acurácia = 1.0000\n","F1-Score = 1.0000\n","\n","Fold 10\n","Acurácia = 1.0000\n","F1-Score = 1.0000\n","\n","Média de Acurácia: 0.9967\n","Desvio Padrão de Acurácia: 0.0100\n","Média de F1-Score: 0.9967\n","Desvio Padrão de F1-Score: 0.0100\n"]}],"source":["# Executando com as duas melhores combinações\n","for params in melhores_parametros:\n","  print(f\"\\nRegressão Logística para os hiperparâmetros: {params}\\n\")\n","\n","  logreg = LogisticRegression(\n","      random_state=42,\n","      max_iter=1000,\n","      C=params['C'],\n","      solver=params['solver']\n","    )\n","\n","  kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n","\n","  accuracies_fold = cross_val_score(logreg, X, y, cv=kf, scoring='accuracy')\n","  f1_scores_fold = cross_val_score(logreg, X, y, cv=kf, scoring='f1_weighted')\n","\n","  for fold, (train_index, test_index) in enumerate(kf.split(X, y), 1):\n","      X_train, X_test = X[train_index], X[test_index]\n","      y_train, y_test = y[train_index], y[test_index]\n","\n","      logreg.fit(X_train, y_train)\n","      y_pred = logreg.predict(X_test)\n","\n","      # Acurácia e o F1-Score do fold atual\n","      print(f\"Fold {fold}\\nAcurácia = {accuracies_fold[fold-1]:.4f}\\nF1-Score = {f1_scores_fold[fold-1]:.4f}\\n\")\n","\n","  # Cálculo das médias e o desvio padrão\n","  media_acuracia = np.mean(accuracies_fold)\n","  desvio_acuracia = np.std(accuracies_fold)\n","\n","  media_f1 = np.mean(f1_scores_fold)\n","  desvio_f1 = np.std(f1_scores_fold)\n","\n","  print(f\"Média de Acurácia: {media_acuracia:.4f}\")\n","  print(f\"Desvio Padrão de Acurácia: {desvio_acuracia:.4f}\")\n","  print(f\"Média de F1-Score: {media_f1:.4f}\")\n","  print(f\"Desvio Padrão de F1-Score: {desvio_f1:.4f}\")"]},{"cell_type":"markdown","metadata":{"id":"sXJd7JGdoFru"},"source":["# Rede Neural MLP"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":372746,"status":"ok","timestamp":1731717710050,"user":{"displayName":"ANNIA LUIZA SEBOLD DE ALMEIDA","userId":"04748302660145563818"},"user_tz":240},"id":"ZRIz9MYjoKtG","outputId":"16446808-e7dc-4761-b195-96000e0484af"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 10 folds for each of 4 candidates, totalling 40 fits\n","Melhores parâmetros encontrados: [{'hidden_layer_sizes': (50, 50), 'learning_rate': 'adaptive'}, {'hidden_layer_sizes': (50, 50), 'learning_rate': 'constant'}]\n"]}],"source":["from sklearn.neural_network import MLPClassifier\n","\n","y = np.array(classes)\n","\n","grid_search = GridSearchCV(\n","    estimator=MLPClassifier(random_state=42,max_iter=200),\n","    param_grid={\n","      'hidden_layer_sizes': [(100,), (50, 50)],  # Diferentes n° de neurônios e camadas\n","      'learning_rate': ['constant', 'adaptive'],  # Tipos de taxa de aprendizado\n","    },\n","    scoring=make_scorer(f1_score, average='weighted'),\n","    cv=10,\n","    n_jobs=1,\n","    verbose=1\n",")\n","\n","grid_search.fit(X, y)\n","\n","resultados = grid_search.cv_results_\n","melhores_indices = np.argsort(resultados['mean_test_score'])[::-1][:2]\n","\n","melhores_parametros = [resultados['params'][idx] for idx in melhores_indices]\n","\n","print(f\"Melhores parâmetros encontrados: {melhores_parametros}\")\n","\n"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":396440,"status":"ok","timestamp":1731718110213,"user":{"displayName":"ANNIA LUIZA SEBOLD DE ALMEIDA","userId":"04748302660145563818"},"user_tz":240},"id":"Kt_mAxtdoabu","outputId":"84d10ec9-0dc0-4235-bb4a-cfb07dd11973"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Rede Neural para os hiperparâmetros: {'hidden_layer_sizes': (50, 50), 'learning_rate': 'adaptive'}\n","\n","Fold 1\n","Acurácia = 1.0000\n","F1-Score = 1.0000\n","\n","Fold 2\n","Acurácia = 1.0000\n","F1-Score = 1.0000\n","\n","Fold 3\n","Acurácia = 1.0000\n","F1-Score = 1.0000\n","\n","Fold 4\n","Acurácia = 1.0000\n","F1-Score = 1.0000\n","\n","Fold 5\n","Acurácia = 0.9333\n","F1-Score = 0.9327\n","\n","Fold 6\n","Acurácia = 1.0000\n","F1-Score = 1.0000\n","\n","Fold 7\n","Acurácia = 1.0000\n","F1-Score = 1.0000\n","\n","Fold 8\n","Acurácia = 1.0000\n","F1-Score = 1.0000\n","\n","Fold 9\n","Acurácia = 1.0000\n","F1-Score = 1.0000\n","\n","Fold 10\n","Acurácia = 1.0000\n","F1-Score = 1.0000\n","\n","Média de Acurácia: 0.9933\n","Desvio Padrão de Acurácia: 0.0200\n","Média de F1-Score: 0.9933\n","Desvio Padrão de F1-Score: 0.0202\n","\n","Rede Neural para os hiperparâmetros: {'hidden_layer_sizes': (50, 50), 'learning_rate': 'constant'}\n","\n","Fold 1\n","Acurácia = 1.0000\n","F1-Score = 1.0000\n","\n","Fold 2\n","Acurácia = 1.0000\n","F1-Score = 1.0000\n","\n","Fold 3\n","Acurácia = 1.0000\n","F1-Score = 1.0000\n","\n","Fold 4\n","Acurácia = 1.0000\n","F1-Score = 1.0000\n","\n","Fold 5\n","Acurácia = 0.9333\n","F1-Score = 0.9327\n","\n","Fold 6\n","Acurácia = 1.0000\n","F1-Score = 1.0000\n","\n","Fold 7\n","Acurácia = 1.0000\n","F1-Score = 1.0000\n","\n","Fold 8\n","Acurácia = 1.0000\n","F1-Score = 1.0000\n","\n","Fold 9\n","Acurácia = 1.0000\n","F1-Score = 1.0000\n","\n","Fold 10\n","Acurácia = 1.0000\n","F1-Score = 1.0000\n","\n","Média de Acurácia: 0.9933\n","Desvio Padrão de Acurácia: 0.0200\n","Média de F1-Score: 0.9933\n","Desvio Padrão de F1-Score: 0.0202\n"]}],"source":["# Executando com as duas melhores combinações\n","for params in melhores_parametros:\n","  print(f\"\\nRede Neural para os hiperparâmetros: {params}\\n\")\n","\n","  mlp = MLPClassifier(\n","    hidden_layer_sizes=params['hidden_layer_sizes'],\n","    learning_rate=params['learning_rate'],\n","    random_state=42,\n","    max_iter=200\n","  )\n","\n","  kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n","\n","  accuracies_fold = cross_val_score(mlp, X, y, cv=kf, scoring='accuracy')\n","  f1_scores_fold = cross_val_score(mlp, X, y, cv=kf, scoring='f1_weighted')\n","\n","  for fold, (train_index, test_index) in enumerate(kf.split(X, y), 1):\n","      X_train, X_test = X[train_index], X[test_index]\n","      y_train, y_test = y[train_index], y[test_index]\n","\n","      mlp.fit(X_train, y_train)\n","      y_pred = mlp.predict(X_test)\n","\n","      # Acurácia e o F1-Score do fold atual\n","      print(f\"Fold {fold}\\nAcurácia = {accuracies_fold[fold-1]:.4f}\\nF1-Score = {f1_scores_fold[fold-1]:.4f}\\n\")\n","\n","  # Cálculo das médias e o desvio padrão\n","  media_acuracia = np.mean(accuracies_fold)\n","  desvio_acuracia = np.std(accuracies_fold)\n","\n","  media_f1 = np.mean(f1_scores_fold)\n","  desvio_f1 = np.std(f1_scores_fold)\n","\n","  print(f\"Média de Acurácia: {media_acuracia:.4f}\")\n","  print(f\"Desvio Padrão de Acurácia: {desvio_acuracia:.4f}\")\n","  print(f\"Média de F1-Score: {media_f1:.4f}\")\n","  print(f\"Desvio Padrão de F1-Score: {desvio_f1:.4f}\")"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
